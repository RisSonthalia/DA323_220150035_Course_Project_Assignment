# Speech2Face Paper Analysis - DA323 Course Project Assignment

## Project Overview
This repository contains my analysis and blog on the "Speech2Face: Learning the Face Behind a Voice" paper by Oh et al. The blog explores how deep learning can be used to reconstruct facial features from voice data, examining both technical aspects and ethical considerations of this technology.

## By
**Name:** Rishab Sonthalia  
**Roll No.:** 220150035

## Contents
The Jupyter notebook in this repository includes:

- **Introduction & Motivation** - Overview of the Speech2Face concept and research goals
- **Historical Background** - Prior work on audio-visual correlations and cross-modal learning
- **Technical Architecture** - Detailed breakdown of the model's components:
  - Voice Encoder Network
  - Face Decoder Network
  - Training methodology
- **Results Analysis** - Evaluation of the model's performance and limitations
- **Personal Reflections** - My thoughts on the implications of this technology
- **Future Improvements** - Potential directions for enhancing the model

## Key Insights
The Speech2Face model demonstrates interesting correlations between voice and physical attributes, though it's designed to capture general facial traits rather than identifying specific individuals. The project examines both the technical achievements and important ethical questions raised by this technology.

## Technologies
- Deep Neural Networks
- Audio Processing (Spectrograms)
- Face Recognition/Reconstruction
- Cross-Modal Learning

## How to Use
1. Clone this repository
2. Open the Jupyter notebook to view the complete analysis
3. Follow along with the markdown sections for a structured exploration of the paper
